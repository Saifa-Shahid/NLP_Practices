{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzzdgV_6mQXE"
   },
   "outputs": [],
   "source": [
    "#newprogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JK8K20dSn90r",
    "outputId": "a5a55dc4-8c88-4b02-8d55-cda229f07c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\saifa\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: regex in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anENHqtKoDgQ",
    "outputId": "57941b41-7ab7-47c9-d640-607ab0b37d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Collecting tinysegmenter==0.3\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from newspaper3k) (3.5)\n",
      "Collecting feedfinder2>=0.0.4\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "Collecting feedparser>=5.2.1\n",
      "  Downloading feedparser-6.0.2-py3-none-any.whl (80 kB)\n",
      "Collecting cssselect>=0.9.2\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from newspaper3k) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\saifa\\appdata\\roaming\\python\\python38\\site-packages (from newspaper3k) (2.8.1)\n",
      "Collecting tldextract>=2.0.1\n",
      "  Downloading tldextract-3.1.0-py2.py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from newspaper3k) (4.9.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from newspaper3k) (2.24.0)\n",
      "Collecting jieba3k>=0.35.1\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from newspaper3k) (5.3.1)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from newspaper3k) (4.5.2)\n",
      "Requirement already satisfied: click in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.47.0)\n",
      "Requirement already satisfied: regex in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2020.6.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (0.16.0)\n",
      "Requirement already satisfied: six in c:\\users\\saifa\\appdata\\roaming\\python\\python38\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "Collecting requests-file>=1.4\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (2.10)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\saifa\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (1.25.9)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13537 sha256=3fdecef1fd76f857883a5faefd2e3534808f0843da8a67a69a6129e049a06ece\n",
      "  Stored in directory: c:\\users\\saifa\\appdata\\local\\pip\\cache\\wheels\\99\\74\\83\\8fac1c8d9c648cfabebbbffe97a889f6624817f3aa0bbe6c09\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3354 sha256=5f42e701b04ee6b2ff22f1673c4271bc35bbd24be6e92d8fc8e7aa2666b1a3a9\n",
      "  Stored in directory: c:\\users\\saifa\\appdata\\local\\pip\\cache\\wheels\\b6\\09\\68\\a9f15498ac02c23dde29f18745bc6a6f574ba4ab41861a3575\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398406 sha256=1cf36f53d3fd64902d2bb81ead5c3e204eec505b991957681d224f526ff5a8cc\n",
      "  Stored in directory: c:\\users\\saifa\\appdata\\local\\pip\\cache\\wheels\\1f\\7e\\0c\\54f3b0f5164278677899f2db08f2b07943ce2d024a3c862afb\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=229558c302e231db44fb517773ba5ee9b084f29c632bb61756b78b67e2dfec18\n",
      "  Stored in directory: c:\\users\\saifa\\appdata\\local\\pip\\cache\\wheels\\83\\63\\2f\\117884c3b19d46b64d3d61690333aa80c88dc14050e269c546\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, feedfinder2, sgmllib3k, feedparser, cssselect, requests-file, tldextract, jieba3k, newspaper3k\n",
      "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.2 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ze15DXb2oU7m"
   },
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8FsYSN5pM_0",
    "outputId": "7bfc03f5-cd2f-4dfe-c67b-2e3144f99041"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt', quiet=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gNvfx8x91u0b"
   },
   "outputs": [],
   "source": [
    "article = Article('https://projects.csail.mit.edu/spatial/Main_Page')\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "corpus = article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnErV98x2_GE",
    "outputId": "20e86413-96b5-4065-8c62-40a80b931b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Spatial Language\n",
      "\n",
      "{{#customtitle:Spatial Language at MIT|Spatial Language at MIT}}\n",
      "\n",
      "Natural language is an intuitive and flexible modality for human-robot interaction. A robot designed to interact naturally with humans must be able to understand instructions without requiring the person to speak in any special way. Understanding language from an untrained user is challenging because we are not asking the human to adapt to the limitations of the system, i.e., to limit their instructions to a small vocabulary or grammar. Rather, we want a system that understands naturalistic language directly as produced by people. For example, we want to build systems that engage in dialog:\n",
      "\n",
      "Person: Wait by the elevator for Steven and bring him to my office.\n",
      "\n",
      "Robot: How do I get to the elevators?\n",
      "\n",
      "Person: You get there by walking down and turning left, going through the grey security door. Continue straight and the elevators should be on your right.\n",
      "\n",
      "Robot: Will do.\n",
      "\n",
      "This problem involves the conversion of natural language into a semantic representation, the grounding of symbols in the environment, and performing dialogue. In the current work, we have focused mostly on the first two aspects.\n",
      "\n",
      "We recently got the system working on a quadrotor helicopter. We extended the topological map to 3d, added some orientation commands like \"Face the windows and shot some videos of it flying around the Stata Center!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The system localizes itself in the map using a laser range finder. For this demo, we've annotated the map with the locations of objects like \"the windows\" and \"room 124,\" but we have a prototype version that uses the camera to detect objects automatically. It uses co-occurrence statistics from Flickr to infer the locations of objects that it can't detect directly. There's an onboard PC running Ubuntu doing control and running the sensors, and an offboard laptop that's running almost everything else. We have also demonstrated our approach on a robotic wheelchair. Below is an example query along with the path that the robot inferred to get to its destination. The full version can be seen here\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We have also demonstrated an approach similar to the local inference algorithm [Kollar 10], but that allows backtracking. A video of this is below (original here\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Maps\n",
      "\n",
      "Along with the system we have developed we have collected an extensive corpus of natural language directions along with maps and data from the environment. In experiments, subjects were asked to give directions from one label to another in this map as if they were giving directions to a friend. We used two different environments: an office environment from two adjoining office buildings, and the lobby/atrium in the first floor of the Stata center. These environments were large and complex. Maps of the environments appear below.\n",
      "\n",
      "Eight floor\n",
      "\n",
      "(office environment) First Floor\n",
      "\n",
      "(Lobby/Atrium)\n",
      "\n",
      "Here are sample directions from the corpus.\n",
      "\n",
      "Eight Floor (office)\n",
      "\n",
      "R17 to R5 - With your back to the windows, walk straight through the door near the elevators. Continue to walk straight, going through one door until you come to an intersection just past a whiteboard. Turn left, turn right, and enter the second door on your right (sign says \"Administrative Assistant\").\n",
      "\n",
      "R19 to R22 - From the lounge with the computers on your left, walk through either short hall and take a right down the hall past the mailboxes on your right. Walk all the way through the atrium and down the hall past the spiral staircase. Turn left at the second door past the glass doors to the elevators. Enter into the Department of Linguistics and Philosophy.\n",
      "\n",
      "R25 to R26 - Walk straight down the hall and turn left at the Department of Linguistics and Philosophy headquarters. Continue walking past the stair case, but look right. After the glass windows (looking at elevators) turn right around the corner into a small corner kitchen.\n",
      "\n",
      "R1 to R19 - You are currently in a large room with windows. When you leave the room, turn left (first left) and go to the end of the hall. Turn right and go to the end of the hall. Turn right and go to the end of the hall (where the gray double doors labeled 36-884Z and 36-884E). Turn left and go through the gray door. Keep going straight until you reach the closed double doors. Go through the double doors and turn right. Walk past a row of colored chairs until you reach a set of wooden cabinets with M&M toys and a boston T map taped on the cabinet. Turn left at the cabinet and walk until you reach the wall of mailboxes (cubbies). At the mailboxes turn right, then take your first left. After you turn left go straight, this room with the orange sofa and chairs is your destination.\n",
      "\n",
      "First Floor (lobby/atrium)\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZZTJWrtc3Ift"
   },
   "outputs": [],
   "source": [
    "text = corpus\n",
    "sentence_list = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfY0Zs7N3lCs",
    "outputId": "3b6416ab-abb7-4866-9f07-eb02b6223309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From Spatial Language\\n\\n{{#customtitle:Spatial Language at MIT|Spatial Language at MIT}}\\n\\nNatural language is an intuitive and flexible modality for human-robot interaction.', 'A robot designed to interact naturally with humans must be able to understand instructions without requiring the person to speak in any special way.', 'Understanding language from an untrained user is challenging because we are not asking the human to adapt to the limitations of the system, i.e., to limit their instructions to a small vocabulary or grammar.', 'Rather, we want a system that understands naturalistic language directly as produced by people.', 'For example, we want to build systems that engage in dialog:\\n\\nPerson: Wait by the elevator for Steven and bring him to my office.', 'Robot: How do I get to the elevators?', 'Person: You get there by walking down and turning left, going through the grey security door.', 'Continue straight and the elevators should be on your right.', 'Robot: Will do.', 'This problem involves the conversion of natural language into a semantic representation, the grounding of symbols in the environment, and performing dialogue.', 'In the current work, we have focused mostly on the first two aspects.', 'We recently got the system working on a quadrotor helicopter.', 'We extended the topological map to 3d, added some orientation commands like \"Face the windows and shot some videos of it flying around the Stata Center!', 'The system localizes itself in the map using a laser range finder.', 'For this demo, we\\'ve annotated the map with the locations of objects like \"the windows\" and \"room 124,\" but we have a prototype version that uses the camera to detect objects automatically.', \"It uses co-occurrence statistics from Flickr to infer the locations of objects that it can't detect directly.\", \"There's an onboard PC running Ubuntu doing control and running the sensors, and an offboard laptop that's running almost everything else.\", 'We have also demonstrated our approach on a robotic wheelchair.', 'Below is an example query along with the path that the robot inferred to get to its destination.', 'The full version can be seen here\\n\\n\\n\\n\\n\\nWe have also demonstrated an approach similar to the local inference algorithm [Kollar 10], but that allows backtracking.', 'A video of this is below (original here\\n\\n\\n\\n\\n\\nMaps\\n\\nAlong with the system we have developed we have collected an extensive corpus of natural language directions along with maps and data from the environment.', 'In experiments, subjects were asked to give directions from one label to another in this map as if they were giving directions to a friend.', 'We used two different environments: an office environment from two adjoining office buildings, and the lobby/atrium in the first floor of the Stata center.', 'These environments were large and complex.', 'Maps of the environments appear below.', 'Eight floor\\n\\n(office environment) First Floor\\n\\n(Lobby/Atrium)\\n\\nHere are sample directions from the corpus.', 'Eight Floor (office)\\n\\nR17 to R5 - With your back to the windows, walk straight through the door near the elevators.', 'Continue to walk straight, going through one door until you come to an intersection just past a whiteboard.', 'Turn left, turn right, and enter the second door on your right (sign says \"Administrative Assistant\").', 'R19 to R22 - From the lounge with the computers on your left, walk through either short hall and take a right down the hall past the mailboxes on your right.', 'Walk all the way through the atrium and down the hall past the spiral staircase.', 'Turn left at the second door past the glass doors to the elevators.', 'Enter into the Department of Linguistics and Philosophy.', 'R25 to R26 - Walk straight down the hall and turn left at the Department of Linguistics and Philosophy headquarters.', 'Continue walking past the stair case, but look right.', 'After the glass windows (looking at elevators) turn right around the corner into a small corner kitchen.', 'R1 to R19 - You are currently in a large room with windows.', 'When you leave the room, turn left (first left) and go to the end of the hall.', 'Turn right and go to the end of the hall.', 'Turn right and go to the end of the hall (where the gray double doors labeled 36-884Z and 36-884E).', 'Turn left and go through the gray door.', 'Keep going straight until you reach the closed double doors.', 'Go through the double doors and turn right.', 'Walk past a row of colored chairs until you reach a set of wooden cabinets with M&M toys and a boston T map taped on the cabinet.', 'Turn left at the cabinet and walk until you reach the wall of mailboxes (cubbies).', 'At the mailboxes turn right, then take your first left.', 'After you turn left go straight, this room with the orange sofa and chairs is your destination.', 'First Floor (lobby/atrium)']\n"
     ]
    }
   ],
   "source": [
    "print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qyEAbYt23nlP"
   },
   "outputs": [],
   "source": [
    "def greeting_response(text):\n",
    "  text = text.lower()\n",
    "\n",
    "  bot_greetings = ['howdy','hi','hello','hola']\n",
    "\n",
    "  user_greetings = ['hi', 'hello','holla','greetings','wassup']\n",
    "\n",
    "  for word in text.split():\n",
    "    if word in user_greetings:\n",
    "      return random.choice(bot_greetings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iRgyhSIgnQrF"
   },
   "outputs": [],
   "source": [
    "def index_sort(list_var):\n",
    "  length = len(list_var)\n",
    "  list_index = list(range(0, length))\n",
    "\n",
    "  x = list_var\n",
    "  for i in range(length):\n",
    "    for j in range(length):\n",
    "      if x[list_index[i]] > x[list_index[j]]:\n",
    "        #swap\n",
    "        temp = list_index[i]\n",
    "        list_index[i] = list_index[j]\n",
    "        list_index[j] = temp\n",
    "\n",
    "  return list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qIPs-5R34YNB"
   },
   "outputs": [],
   "source": [
    "def bot_response(user_input):\n",
    "  user_input = user_input.lower()\n",
    "  sentence_list.append(user_input)\n",
    "  bot_response = ''\n",
    "  cm = CountVectorizer().fit_transform(sentence_list)\n",
    "  similarity_scores = cosine_similarity(cm[-1],cm)\n",
    "  similarity_scores_list = similarity_scores.flatten()\n",
    "  index = index_sort(similarity_scores_list)\n",
    "  index = index[1:]\n",
    "  response_flag = 0 \n",
    "\n",
    "  j = 0\n",
    "  for i in range(len(index)):\n",
    "    if similarity_scores_list[index[i]] > 0.0:\n",
    "      bot_response = bot_response+' '+sentence_list[index[i]]\n",
    "      response_flag = 1\n",
    "      j = j+1\n",
    "    if j > 2:\n",
    "      break \n",
    "\n",
    "  if response_flag == 0:\n",
    "    bot_response = bot_response+' '+\"I apologise, I don't understand.\"\n",
    "\n",
    "  sentence_list.remove(user_input)\n",
    "\n",
    "  return bot_response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHHpXpo71Xl_",
    "outputId": "95ba2b8c-2e5d-4364-e9f0-699d458592b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Bot: I am Doctor Bot for short. I will answer your queries about chronic kidney disease. If you want to exit, type bye\n",
      "hello\n",
      "Doc Bot: hello\n",
      "tell me about kidney\n",
      "Doc Bot:  I apologise, I don't understand.\n",
      "bye\n",
      "Doc Bot: Chat with you later\n"
     ]
    }
   ],
   "source": [
    "#start chat\n",
    "\n",
    "print('Doc Bot: I am Doctor Bot for short. I will answer your queries about chronic kidney disease. If you want to exit, type bye') \n",
    "\n",
    "exit_list = ['exit', 'bye', 'quit']\n",
    "\n",
    "while(True):\n",
    "  user_input = input()\n",
    "  if user_input.lower() in exit_list:\n",
    "    print('Doc Bot: Chat with you later')\n",
    "    break\n",
    "  else:\n",
    "    if greeting_response(user_input) != None:\n",
    "      print('Doc Bot: '+greeting_response(user_input))\n",
    "    else:\n",
    "      print('Doc Bot: '+bot_response(user_input)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DocBot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
